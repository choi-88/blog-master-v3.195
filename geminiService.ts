
import { GoogleGenAI, Type } from "@google/genai";
import { BlogInputs, BlogPost, ImageResult, ProductImageData, PersonaAnswers } from "./types";

/**
 * Gemini API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
 */
export const generateInpaintedImage = async (
  originalImage: ProductImageData,
  backgroundLocation: string,
  backgroundColor: string,
  backgroundMaterial: string,
  backgroundDish: string,
  imgReq: { nanoPrompt: string; description: string },
  index: number,
  mainKeyword: string,
  globalBackgroundDNA: string
): Promise<ImageResult> => {
  try {
    const API_KEY = import.meta.env.VITE_OPENROUTER_API_KEY;
    
    // ğŸ’¡ ì˜¤í”ˆë¼ìš°í„°ìš© ëª¨ë¸ ì´ë¦„ (ë³´ìœ í•˜ì‹  ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ë¡œ ì„¤ì •)
    const modelName = "google/gemini-2.0-flash-001"; 

    const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${API_KEY}`,
        "HTTP-Referer": window.location.origin, // ì˜¤í”ˆë¼ìš°í„° í•„ìˆ˜ í—¤ë”
        "X-Title": "Blog Master App",          // ì˜¤í”ˆë¼ìš°í„° í•„ìˆ˜ í—¤ë”
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        "model": modelName,
        "messages": [
          {
            "role": "user",
            "content": [
              {
                "type": "text",
                "text": `TASK: AMATEUR IPHONE SNAPSHOT INPAINTING.
                
                STRICT RULES:
                1. PRODUCT PRESERVATION: NEVER change the product's shape, design, logo, texture, or geometry.
                2. BACKGROUND REPLACEMENT: Replace with "${backgroundLocation}".
                3. SURFACE & STYLING: ${backgroundDish} on "${backgroundMaterial}" texture.
                4. COLOR THEME: "${backgroundColor}" palette.
                5. AESTHETIC STYLE: ${globalBackgroundDNA}. (iPhone 13 Pro look).
                6. PHOTO QUALITY: Natural shadows, realistic mobile lens.
                
                SCENE DETAIL & CAMERA PERSPECTIVE: ${imgReq.nanoPrompt}`
              },
              {
                "type": "image_url",
                "image_url": {
                  "url": `data:${originalImage.mimeType};base64,${originalImage.data}`
                }
              }
            ]
          }
        ]
      })
    });

    const result = await response.json();
    
    if (result.error) {
      throw new Error(result.error.message || "ì˜¤í”ˆë¼ìš°í„° í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ");
    }

    // ì˜¤í”ˆë¼ìš°í„°ê°€ ë°˜í™˜í•œ ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ URL ë˜ëŠ” ì‘ë‹µ ë‚´ìš© ì¶”ì¶œ
    // (ì°¸ê³ : ëª¨ë¸ì— ë”°ë¼ base64 ë°ì´í„°ë¥¼ ë‹¤ì‹œ ì¤„ ìˆ˜ë„ ìˆê³ , URLì„ ì¤„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤)
    let imageUrl = result.choices?.[0]?.message?.content || "";

    // ë§Œì•½ ì‘ë‹µì´ URL í˜•íƒœê°€ ì•„ë‹ˆë¼ë©´ ì ì ˆíˆ ì²˜ë¦¬ (ë³´í†µ ìƒì„± ëª¨ë¸ì€ ê²°ê³¼ë¬¼ì„ ì¤ë‹ˆë‹¤)
    if (!imageUrl) throw new Error("AIê°€ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");

    return {
      url: imageUrl,
      filename: `${mainKeyword.replace(/[^\wê°€-í£]/g, '_')}_${index + 1}.png`,
      description: imgReq.description,
      nanoPrompt: imgReq.nanoPrompt
    };

  } catch (error: any) {
    console.error("Image generation failed:", error);
    return {
      url: '',
      filename: `failed_${index}.png`,
      description: 'ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨',
      nanoPrompt: ''
    };
  }
};

/**
 * ì „ì²´ ë¸”ë¡œê·¸ ì‹œìŠ¤í…œ ìƒì„± ë¡œì§ (SEO/GEO ìµœì í™” ê°•í™”)
 */
export const generateBlogSystem = async (inputs: BlogInputs, skipImages: boolean = false): Promise<BlogPost> => {
  const isImageOnly = inputs.generationMode === 'IMAGE_ONLY';
  
  const systemInstruction = isImageOnly 
  ? `[Role: Professional Product Photographer & Prompt Engineer]
     Your task is to generate high-quality image prompts for product background replacement (inpainting).
     Provide diverse angles: close-up, 45-degree, top-down, context-rich scenes.
     The background should match the theme: ${inputs.backgroundLocation}.
     DO NOT write any blog post content. Keep the 'body' and 'title' properties simple or short summaries of the images.
     Focus on providing excellent 'imagePrompts'.`
  : `[Role: Naver Blog SEO & GEO Content Master (Search Snippet Optimization Expert)]
    
    STRICT CONTENT RULES:
    1. LOGICAL HIERARCHY: Use Markdown ## and ### for subheadings. 
       - DO NOT use square brackets [] or any special characters in subheadings.
       - Use large font headers to separate context clearly.
    2. ANSWER-FIRST: Within the first 200 characters of the post, provide a direct and clear answer/conclusion to the user's search intent. This is critical for GEO (AI Overviews) optimization.
    3. FACTUAL DATA (TABLES): Performance, price, and specs MUST be presented in a Markdown Table format. Avoid vague adjectives; use specific numbers (e.g., 400W, 3 seconds).
    4. E-E-A-T & ORIGINALITY: Include "Personal Experience" and "Unique Insights" that sound like a real user. Do not repeat typical AI-style descriptions.
    5. SEMANTIC LINKING: Naturally mention related entities, competitors, or higher/lower product categories.
    6. CONTENT FLOW: If the user provides a specific "Content Flow" or direction, you MUST strictly follow that narrative structure while maintaining SEO/GEO quality.
    
    FORBIDDEN CHARACTERS:
    - DO NOT use the asterisk symbol (*) anywhere in the entire post. Not even for bolding (**), italicizing, or bullet points.
    - For bolding, use headers or context. 
    - For lists, use numbered lists (1. 2.) or hyphens (-).
    
    ALT-TEXT & IMAGE PLACEHOLDERS:
    - Insert [ì´ë¯¸ì§€ ì„¤ëª…: {description}] at relevant points in the text.

    FINAL OUTPUT:
    - At the end of the post, append the "Final Content Checklist" with all items marked as [x].`;

  const prompt = isImageOnly 
  ? `Generate ${inputs.targetImageCount} diverse image prompts for background synthesis.
     Product: ${inputs.productName}
     Main Keyword: ${inputs.mainKeyword}
     Theme: ${inputs.backgroundLocation}
     Material: ${inputs.backgroundMaterial}
     Dish Style: ${inputs.backgroundDish}
     `
  : `ì œí’ˆëª…: ${inputs.productName}
    ë©”ì¸ í‚¤ì›Œë“œ: ${inputs.mainKeyword}
    ì„œë¸Œ í‚¤ì›Œë“œ: ${inputs.subKeywords}
    ì°¸ê³  URL: ${inputs.referenceLink || 'ì—†ìŒ'}
    ì‡¼í•‘ ë§í¬: ${inputs.productLink || 'https://shoppingconnect.co.kr/'}
    ìƒì„± ì´ë¯¸ì§€ ìˆ˜ëŸ‰: ${inputs.targetImageCount}
    ë°°ê²½ í…Œë§ˆ: ${inputs.backgroundLocation}
    ë°°ê²½ ìƒ‰ê°: ${inputs.backgroundColor}
    ë°”ë‹¥ ì¬ì§ˆ: ${inputs.backgroundMaterial}
    ê·¸ë¦‡ ìŠ¤íƒ€ì¼: ${inputs.backgroundDish}

    [í˜ë¥´ì†Œë‚˜ ë° íë¦„ ì„¤ì •]
    íƒ€ê²Ÿ ë…ì: ${inputs.persona.targetAudience}
    í˜ì¸ í¬ì¸íŠ¸: ${inputs.persona.painPoint}
    í•µì‹¬ í˜œíƒ: ${inputs.persona.solutionBenefit}
    ê¸€ì˜ í†¤: ${inputs.persona.writingTone}
    ì›í•˜ëŠ” ê¸€ì˜ íë¦„/ë°©í–¥: ${inputs.persona.contentFlow || 'AI ì¶”ì²œ ìµœì  íë¦„'}
    CTA: ${inputs.persona.callToAction}

    ì‘ì—… ì§€ì‹œ:
    1. ìµœì í™”ëœ ì½˜í…ì¸ ì˜ 5ëŒ€ í•„ìˆ˜ ì¡°ê±´ì„ ì¤€ìˆ˜í•˜ì—¬ 1,500ì ì´ìƒì˜ ê³ í’ˆì§ˆ ì›ê³ ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    2. ì œëª©ì€ 25ì ë‚´ì™¸ë¡œ ë©”ì¸ í‚¤ì›Œë“œë¥¼ ì „ë©´ì— ë°°ì¹˜í•˜ì„¸ìš”.
    3. ë³¸ë¬¸ì— ë°˜ë“œì‹œ ì œí’ˆ ì •ë³´ë¥¼ ìš”ì•½í•œ Markdown í‘œ(Table)ë¥¼ í¬í•¨í•˜ì„¸ìš”.
    4. '*' ê¸°í˜¸ì™€ ì†Œì œëª©ì˜ '[]'ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
    5. ì‚¬ìš©ìê°€ ìš”ì²­í•œ 'ì›í•˜ëŠ” ê¸€ì˜ íë¦„/ë°©í–¥'ì´ ìˆë‹¤ë©´ ì´ë¥¼ ì›ê³ ì˜ ì „ê°œ êµ¬ì¡°ì— ì ê·¹ ë°˜ì˜í•˜ì„¸ìš”.
    6. ë³¸ë¬¸ í•˜ë‹¨ì— 'ìµœì¢… ì½˜í…ì¸  ì²´í¬ë¦¬ìŠ¤íŠ¸'ë¥¼ í¬í•¨í•˜ì—¬ í’ˆì§ˆì„ ë³´ì¦í•˜ì„¸ìš”.`;

  const schema = {
    type: Type.OBJECT,
    properties: {
      globalBackgroundDNA: { type: Type.STRING },
      title: { type: Type.STRING },
      body: { type: Type.STRING },
      persona: {
        type: Type.OBJECT,
        properties: {
          targetAudience: { type: Type.STRING },
          painPoint: { type: Type.STRING },
          solutionBenefit: { type: Type.STRING },
          writingTone: { type: Type.STRING },
          callToAction: { type: Type.STRING },
          contentFlow: { type: Type.STRING }
        },
        required: ["targetAudience", "painPoint", "solutionBenefit", "writingTone", "callToAction", "contentFlow"]
      },
      report: {
        type: Type.OBJECT,
        properties: {
          rankingProbability: { type: Type.NUMBER },
          safetyIndex: { type: Type.NUMBER },
          suggestedCategory: { type: Type.STRING },
          analysisSummary: { type: Type.STRING },
          personaAnalysis: { type: Type.STRING },
          avgWordCount: { type: Type.NUMBER }
        },
        required: ["rankingProbability", "safetyIndex", "suggestedCategory", "analysisSummary", "personaAnalysis", "avgWordCount"]
      },
      imagePrompts: {
        type: Type.ARRAY,
        items: {
          type: Type.OBJECT,
          properties: {
            description: { type: Type.STRING },
            nanoPrompt: { type: Type.STRING }
          },
          required: ["description", "nanoPrompt"]
        }
      }
    },
    required: ["globalBackgroundDNA", "title", "body", "persona", "report", "imagePrompts"]
  };

  try {
    const ai = getGeminiClient();
    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: prompt,
      config: {
        systemInstruction,
        tools: [{ googleSearch: {} }],
        responseMimeType: "application/json",
        responseSchema: schema
      }
    });
    
    const rawData = JSON.parse(response.text || '{}');
    const dna = rawData.globalBackgroundDNA || "Natural iPhone 13 Pro snapshot";

    let finalImages: ImageResult[] = [];
    if (!skipImages) {
      const imageTasks = Array.from({ length: inputs.targetImageCount }).map((_, idx) => {
        const imgIdx = idx % inputs.productImages.length;
        const originalImage = inputs.productImages[imgIdx];
        const imgReq = rawData.imagePrompts[idx] || { 
          nanoPrompt: "Casual snapshot", 
          description: `ì´ë¯¸ì§€ ì„¤ëª…: ${idx + 1}` 
        };
        const currentDishStyle = (idx < inputs.dishImageCount) ? inputs.backgroundDish : "placed directly on the surface";
        return generateInpaintedImage(originalImage, inputs.backgroundLocation, inputs.backgroundColor, inputs.backgroundMaterial, currentDishStyle, imgReq, idx, inputs.mainKeyword || inputs.productName, dna);
      });
      const imageResults = await Promise.all(imageTasks);
      finalImages = imageResults.filter(img => img.url !== '');
    }

    return {
      title: isImageOnly ? `${inputs.productName} ì´ë¯¸ì§€ ìƒì„± ê²°ê³¼` : rawData.title,
      content: isImageOnly ? "ì´ë¯¸ì§€ ì „ìš© ëª¨ë“œë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤." : rawData.body,
      persona: rawData.persona,
      mode: inputs.generationMode,
      report: {
        ...rawData.report,
        requiredImageCount: finalImages.length,
        personaAnalysis: dna,
        analysisSummary: isImageOnly ? "ì´ë¯¸ì§€ ì „ìš© ëª¨ë“œë¡œ í•©ì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤." : `SEO/GEO ìµœì í™” 5ëŒ€ ì¡°ê±´ ë° ì‚¬ìš©ì ìš”ì²­ íë¦„ì´ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.`
      },
      images: finalImages,
      groundingSources: response.candidates?.[0]?.groundingMetadata?.groundingChunks?.map((chunk: any) => chunk.web ? { title: chunk.web.title, url: chunk.web.uri } : null).filter(Boolean) || []
    };
  } catch (e: any) {
    console.error("System generation error:", e);
    throw new Error(`ì½˜í…ì¸  ìƒì„± ì˜¤ë¥˜: ${e.message}`);
  }
};
